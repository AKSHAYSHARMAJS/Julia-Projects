{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bearing-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using ScikitLearn: fit!, predict, @sk_import\n",
    "using CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-controversy",
   "metadata": {},
   "source": [
    "Loading Car evaluation dataset\n",
    "\n",
    "Dataset contains 1,728 rows × 7 columns\n",
    "\n",
    "(may take around a minute if loading the data for the first time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "compound-tract",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>buying</th><th>maint</th><th>doors</th><th>persons</th><th>lug_boot</th><th>safety</th><th>class_values</th></tr><tr><th></th><th>String</th><th>String</th><th>String</th><th>String</th><th>String</th><th>String</th><th>String</th></tr></thead><tbody><p>1,728 rows × 7 columns</p><tr><th>1</th><td>vhigh</td><td>vhigh</td><td>2</td><td>2</td><td>small</td><td>low</td><td>unacc</td></tr><tr><th>2</th><td>vhigh</td><td>vhigh</td><td>2</td><td>2</td><td>small</td><td>med</td><td>unacc</td></tr><tr><th>3</th><td>vhigh</td><td>vhigh</td><td>2</td><td>2</td><td>small</td><td>high</td><td>unacc</td></tr><tr><th>4</th><td>vhigh</td><td>vhigh</td><td>2</td><td>2</td><td>med</td><td>low</td><td>unacc</td></tr><tr><th>5</th><td>vhigh</td><td>vhigh</td><td>2</td><td>2</td><td>med</td><td>med</td><td>unacc</td></tr><tr><th>6</th><td>vhigh</td><td>vhigh</td><td>2</td><td>2</td><td>med</td><td>high</td><td>unacc</td></tr><tr><th>7</th><td>vhigh</td><td>vhigh</td><td>2</td><td>2</td><td>big</td><td>low</td><td>unacc</td></tr><tr><th>8</th><td>vhigh</td><td>vhigh</td><td>2</td><td>2</td><td>big</td><td>med</td><td>unacc</td></tr><tr><th>9</th><td>vhigh</td><td>vhigh</td><td>2</td><td>2</td><td>big</td><td>high</td><td>unacc</td></tr><tr><th>10</th><td>vhigh</td><td>vhigh</td><td>2</td><td>4</td><td>small</td><td>low</td><td>unacc</td></tr><tr><th>11</th><td>vhigh</td><td>vhigh</td><td>2</td><td>4</td><td>small</td><td>med</td><td>unacc</td></tr><tr><th>12</th><td>vhigh</td><td>vhigh</td><td>2</td><td>4</td><td>small</td><td>high</td><td>unacc</td></tr><tr><th>13</th><td>vhigh</td><td>vhigh</td><td>2</td><td>4</td><td>med</td><td>low</td><td>unacc</td></tr><tr><th>14</th><td>vhigh</td><td>vhigh</td><td>2</td><td>4</td><td>med</td><td>med</td><td>unacc</td></tr><tr><th>15</th><td>vhigh</td><td>vhigh</td><td>2</td><td>4</td><td>med</td><td>high</td><td>unacc</td></tr><tr><th>16</th><td>vhigh</td><td>vhigh</td><td>2</td><td>4</td><td>big</td><td>low</td><td>unacc</td></tr><tr><th>17</th><td>vhigh</td><td>vhigh</td><td>2</td><td>4</td><td>big</td><td>med</td><td>unacc</td></tr><tr><th>18</th><td>vhigh</td><td>vhigh</td><td>2</td><td>4</td><td>big</td><td>high</td><td>unacc</td></tr><tr><th>19</th><td>vhigh</td><td>vhigh</td><td>2</td><td>more</td><td>small</td><td>low</td><td>unacc</td></tr><tr><th>20</th><td>vhigh</td><td>vhigh</td><td>2</td><td>more</td><td>small</td><td>med</td><td>unacc</td></tr><tr><th>21</th><td>vhigh</td><td>vhigh</td><td>2</td><td>more</td><td>small</td><td>high</td><td>unacc</td></tr><tr><th>22</th><td>vhigh</td><td>vhigh</td><td>2</td><td>more</td><td>med</td><td>low</td><td>unacc</td></tr><tr><th>23</th><td>vhigh</td><td>vhigh</td><td>2</td><td>more</td><td>med</td><td>med</td><td>unacc</td></tr><tr><th>24</th><td>vhigh</td><td>vhigh</td><td>2</td><td>more</td><td>med</td><td>high</td><td>unacc</td></tr><tr><th>25</th><td>vhigh</td><td>vhigh</td><td>2</td><td>more</td><td>big</td><td>low</td><td>unacc</td></tr><tr><th>26</th><td>vhigh</td><td>vhigh</td><td>2</td><td>more</td><td>big</td><td>med</td><td>unacc</td></tr><tr><th>27</th><td>vhigh</td><td>vhigh</td><td>2</td><td>more</td><td>big</td><td>high</td><td>unacc</td></tr><tr><th>28</th><td>vhigh</td><td>vhigh</td><td>3</td><td>2</td><td>small</td><td>low</td><td>unacc</td></tr><tr><th>29</th><td>vhigh</td><td>vhigh</td><td>3</td><td>2</td><td>small</td><td>med</td><td>unacc</td></tr><tr><th>30</th><td>vhigh</td><td>vhigh</td><td>3</td><td>2</td><td>small</td><td>high</td><td>unacc</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& buying & maint & doors & persons & lug\\_boot & safety & class\\_values\\\\\n",
       "\t\\hline\n",
       "\t& String & String & String & String & String & String & String\\\\\n",
       "\t\\hline\n",
       "\t1 & vhigh & vhigh & 2 & 2 & small & low & unacc \\\\\n",
       "\t2 & vhigh & vhigh & 2 & 2 & small & med & unacc \\\\\n",
       "\t3 & vhigh & vhigh & 2 & 2 & small & high & unacc \\\\\n",
       "\t4 & vhigh & vhigh & 2 & 2 & med & low & unacc \\\\\n",
       "\t5 & vhigh & vhigh & 2 & 2 & med & med & unacc \\\\\n",
       "\t6 & vhigh & vhigh & 2 & 2 & med & high & unacc \\\\\n",
       "\t7 & vhigh & vhigh & 2 & 2 & big & low & unacc \\\\\n",
       "\t8 & vhigh & vhigh & 2 & 2 & big & med & unacc \\\\\n",
       "\t9 & vhigh & vhigh & 2 & 2 & big & high & unacc \\\\\n",
       "\t10 & vhigh & vhigh & 2 & 4 & small & low & unacc \\\\\n",
       "\t11 & vhigh & vhigh & 2 & 4 & small & med & unacc \\\\\n",
       "\t12 & vhigh & vhigh & 2 & 4 & small & high & unacc \\\\\n",
       "\t13 & vhigh & vhigh & 2 & 4 & med & low & unacc \\\\\n",
       "\t14 & vhigh & vhigh & 2 & 4 & med & med & unacc \\\\\n",
       "\t15 & vhigh & vhigh & 2 & 4 & med & high & unacc \\\\\n",
       "\t16 & vhigh & vhigh & 2 & 4 & big & low & unacc \\\\\n",
       "\t17 & vhigh & vhigh & 2 & 4 & big & med & unacc \\\\\n",
       "\t18 & vhigh & vhigh & 2 & 4 & big & high & unacc \\\\\n",
       "\t19 & vhigh & vhigh & 2 & more & small & low & unacc \\\\\n",
       "\t20 & vhigh & vhigh & 2 & more & small & med & unacc \\\\\n",
       "\t21 & vhigh & vhigh & 2 & more & small & high & unacc \\\\\n",
       "\t22 & vhigh & vhigh & 2 & more & med & low & unacc \\\\\n",
       "\t23 & vhigh & vhigh & 2 & more & med & med & unacc \\\\\n",
       "\t24 & vhigh & vhigh & 2 & more & med & high & unacc \\\\\n",
       "\t25 & vhigh & vhigh & 2 & more & big & low & unacc \\\\\n",
       "\t26 & vhigh & vhigh & 2 & more & big & med & unacc \\\\\n",
       "\t27 & vhigh & vhigh & 2 & more & big & high & unacc \\\\\n",
       "\t28 & vhigh & vhigh & 3 & 2 & small & low & unacc \\\\\n",
       "\t29 & vhigh & vhigh & 3 & 2 & small & med & unacc \\\\\n",
       "\t30 & vhigh & vhigh & 3 & 2 & small & high & unacc \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m1728×7 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m buying \u001b[0m\u001b[1m maint  \u001b[0m\u001b[1m doors  \u001b[0m\u001b[1m persons \u001b[0m\u001b[1m lug_boot \u001b[0m\u001b[1m safety \u001b[0m\u001b[1m class_values \u001b[0m\n",
       "\u001b[1m      \u001b[0m│\u001b[90m String \u001b[0m\u001b[90m String \u001b[0m\u001b[90m String \u001b[0m\u001b[90m String  \u001b[0m\u001b[90m String   \u001b[0m\u001b[90m String \u001b[0m\u001b[90m String       \u001b[0m\n",
       "──────┼─────────────────────────────────────────────────────────────────\n",
       "    1 │ vhigh   vhigh   2       2        small     low     unacc\n",
       "    2 │ vhigh   vhigh   2       2        small     med     unacc\n",
       "    3 │ vhigh   vhigh   2       2        small     high    unacc\n",
       "    4 │ vhigh   vhigh   2       2        med       low     unacc\n",
       "    5 │ vhigh   vhigh   2       2        med       med     unacc\n",
       "    6 │ vhigh   vhigh   2       2        med       high    unacc\n",
       "    7 │ vhigh   vhigh   2       2        big       low     unacc\n",
       "    8 │ vhigh   vhigh   2       2        big       med     unacc\n",
       "    9 │ vhigh   vhigh   2       2        big       high    unacc\n",
       "   10 │ vhigh   vhigh   2       4        small     low     unacc\n",
       "   11 │ vhigh   vhigh   2       4        small     med     unacc\n",
       "  ⋮   │   ⋮       ⋮       ⋮        ⋮        ⋮        ⋮          ⋮\n",
       " 1719 │ low     low     5more   4        big       high    vgood\n",
       " 1720 │ low     low     5more   more     small     low     unacc\n",
       " 1721 │ low     low     5more   more     small     med     acc\n",
       " 1722 │ low     low     5more   more     small     high    good\n",
       " 1723 │ low     low     5more   more     med       low     unacc\n",
       " 1724 │ low     low     5more   more     med       med     good\n",
       " 1725 │ low     low     5more   more     med       high    vgood\n",
       " 1726 │ low     low     5more   more     big       low     unacc\n",
       " 1727 │ low     low     5more   more     big       med     good\n",
       " 1728 │ low     low     5more   more     big       high    vgood\n",
       "\u001b[36m                                                       1707 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DataFrame(CSV.File(\"car.data\"; header=[\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\",\"class_values\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-belize",
   "metadata": {},
   "source": [
    "Encoding all categorical data(string type) that helps in training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "toxic-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "@sk_import preprocessing: LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "for i = 1:7\n",
    "    data[!,i] = enc.fit_transform(data[!,i])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-coaching",
   "metadata": {},
   "source": [
    "Converting DataFrame to Arrays and splitting input columns(x) and output column(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "exclusive-roller",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1728-element Array{Int64,1}:\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " ⋮\n",
       " 2\n",
       " 1\n",
       " 3\n",
       " 2\n",
       " 0\n",
       " 1\n",
       " 2\n",
       " 1\n",
       " 3\n",
       " 2\n",
       " 1\n",
       " 3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x = convert(Array, data[:,[1,2,3,4,5,6]])\n",
    "data_y = convert(Array, data[:,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-record",
   "metadata": {},
   "source": [
    "Splitting data into training and testing sub-datasets with 70/30 split respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "outstanding-heating",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Module model_selection has been ported to Julia - try `import ScikitLearn: CrossValidation` instead\n",
      "└ @ ScikitLearn.Skcore /Users/akshaysharma/.julia/packages/ScikitLearn/NJwUf/src/Skcore.jl:179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4-element Array{Array{Int64,N} where N,1}:\n",
       " [1 0 … 1 1; 0 1 … 1 0; … ; 3 2 … 2 2; 2 0 … 0 0]\n",
       " [2 1 … 2 1; 0 0 … 0 2; … ; 0 3 … 1 0; 3 1 … 0 0]\n",
       " [2, 0, 2, 1, 2, 2, 0, 2, 2, 0  …  2, 2, 2, 2, 1, 0, 0, 0, 2, 2]\n",
       " [2, 0, 2, 2, 2, 0, 2, 2, 0, 2  …  2, 2, 2, 2, 2, 2, 2, 2, 2, 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@sk_import model_selection: train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-myanmar",
   "metadata": {},
   "source": [
    "# Naive Bayesian Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ongoing-judge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject CategoricalNB()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@sk_import naive_bayes: CategoricalNB\n",
    "model = CategoricalNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "narrative-amount",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject CategoricalNB()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-alpha",
   "metadata": {},
   "source": [
    "### Performance on Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "legendary-third",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.028887 seconds (28.77 k allocations: 1.557 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "519-element Array{Int64,1}:\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " ⋮\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time predictions_test = predict(model, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "circular-playback",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8689788053949904"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@sk_import metrics: accuracy_score\n",
    "accuracy = accuracy_score(predictions_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-avatar",
   "metadata": {},
   "source": [
    "### Performance on Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "checked-promotion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000969 seconds (36 allocations: 11.312 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1209-element Array{Int64,1}:\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 2\n",
       " 1\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " ⋮\n",
       " 0\n",
       " 0\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 2\n",
       " 2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time predictions_train = predict(model, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "instant-disease",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant accuracy_score. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8817204301075269"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@sk_import metrics: accuracy_score\n",
    "accuracy = accuracy_score(predictions_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-supplement",
   "metadata": {},
   "source": [
    "**Size of Naive bayesian model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "nonprofit-brooks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2424 bytes"
     ]
    }
   ],
   "source": [
    "using PyCall\n",
    "@pyimport pickle\n",
    "p = pickle.dumps(model)\n",
    "print(sizeof(p),\" bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-watch",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "russian-correlation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject DecisionTreeClassifier()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@sk_import tree: DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "theoretical-plant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject DecisionTreeClassifier()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-stack",
   "metadata": {},
   "source": [
    "### Performance On Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "advised-present",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000549 seconds (36 allocations: 5.875 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "519-element Array{Int64,1}:\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 2\n",
       " ⋮\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time predictions_test = predict(model, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "broke-shakespeare",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant accuracy_score. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9691714836223507"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@sk_import metrics: accuracy_score\n",
    "accuracy = accuracy_score(predictions_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-wireless",
   "metadata": {},
   "source": [
    "### Performance On Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "weekly-interference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000589 seconds (36 allocations: 11.312 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1209-element Array{Int64,1}:\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 1\n",
       " 2\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " ⋮\n",
       " 0\n",
       " 3\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 2\n",
       " 2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time predictions_train = predict(model, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "indoor-nightmare",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant accuracy_score. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@sk_import metrics: accuracy_score\n",
    "accuracy = accuracy_score(predictions_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-simon",
   "metadata": {},
   "source": [
    "**Size of Decision tree model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "unsigned-sympathy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14757 bytes"
     ]
    }
   ],
   "source": [
    "using PyCall\n",
    "@pyimport pickle\n",
    "p = pickle.dumps(model)\n",
    "print(sizeof(p),\" bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-frank",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "silent-shooting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject LinearSVC()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@sk_import svm: LinearSVC\n",
    "model = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sorted-distinction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject LinearSVC()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-peace",
   "metadata": {},
   "source": [
    "### Performance on Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "narrative-secretariat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.002837 seconds (39 allocations: 7.250 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "519-element Array{Int64,1}:\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " ⋮\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time predictions_test = predict(model, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sunset-sailing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant accuracy_score. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6955684007707129"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@sk_import metrics: accuracy_score\n",
    "accuracy = accuracy_score(predictions_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-permit",
   "metadata": {},
   "source": [
    "### Performance on Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "atlantic-calcium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000658 seconds (36 allocations: 11.312 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1209-element Array{Int64,1}:\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " ⋮\n",
       " 0\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time predictions_train = predict(model, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "residential-brother",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant accuracy_score. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6989247311827957"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@sk_import metrics: accuracy_score\n",
    "accuracy = accuracy_score(predictions_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-being",
   "metadata": {},
   "source": [
    "**Size of support vector machine model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adverse-folks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884 bytes"
     ]
    }
   ],
   "source": [
    "using PyCall\n",
    "@pyimport pickle\n",
    "p = pickle.dumps(model)\n",
    "print(sizeof(p),\" bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-vatican",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "falling-mattress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject MLPClassifier()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@sk_import neural_network: MLPClassifier\n",
    "model = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "compound-boulder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.696584 seconds (21 allocations: 1.109 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyObject MLPClassifier()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time fit!(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-monte",
   "metadata": {},
   "source": [
    "### Performance On Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "danish-shuttle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.003514 seconds (36 allocations: 5.875 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "519-element Array{Int64,1}:\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 2\n",
       " ⋮\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time predictions_test = predict(model, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "opponent-waterproof",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant accuracy_score. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8689788053949904"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@sk_import metrics: accuracy_score\n",
    "accuracy = accuracy_score(predictions_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-aberdeen",
   "metadata": {},
   "source": [
    "### Performance On Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "serial-marathon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.003493 seconds (36 allocations: 11.312 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1209-element Array{Int64,1}:\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " ⋮\n",
       " 0\n",
       " 0\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 0\n",
       " 2\n",
       " 0\n",
       " 0\n",
       " 2\n",
       " 2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time predictions_train = predict(model, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "described-piano",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant accuracy_score. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9007444168734491"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@sk_import metrics: accuracy_score\n",
    "accuracy = accuracy_score(predictions_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-discretion",
   "metadata": {},
   "source": [
    "**Size of neural network model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "expensive-importance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34777 bytes"
     ]
    }
   ],
   "source": [
    "using PyCall\n",
    "@pyimport pickle\n",
    "p = pickle.dumps(model)\n",
    "print(sizeof(p),\" bytes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
